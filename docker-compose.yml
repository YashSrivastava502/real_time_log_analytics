version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    depends_on:
      - zookeeper

  kafka-init:
    image: wurstmeister/kafka:2.12-2.2.1
    depends_on:
      - kafka
    command: >
      sh -c "sleep 10 &&
             kafka-topics.sh --create --if-not-exists --topic logs
             --bootstrap-server kafka:9092
             --partitions 1 --replication-factor 1"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.1
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

  producer:
    build: ./kafka
    depends_on:
      - kafka-init
    command: ["python", "producer.py"]

  spark:
    image: bitnami/spark:3.5.0
    depends_on:
      - kafka-init
      - elasticsearch
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark
    volumes:
      - ./spark:/opt/spark-apps
    command: >
      spark-submit
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.12.1
      /opt/spark-apps/log_stream.py
    ports:
      - "7077:7077"
      - "8080:8080"
